{"cells":[{"cell_type":"markdown","source":["\n","## Ensure that you are executing the notebooks using Spark 3.3."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"395bd8dc-b390-4eb7-8e37-9dc5d11b6b00"},{"cell_type":"markdown","source":["### Spark session configuration\n","This cell sets Spark session settings to enable _Verti-Parquet_ and _Optimize on Write_. More details about _Verti-Parquet_ and _Optimize on Write_ in tutorial document."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"521cbb16-d2ed-4eae-9d19-52d5b5267d7a"},{"cell_type":"code","source":["spark.conf.set(\"sprk.sql.parquet.vorder.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.binSize\", \"1073741824\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"983b9feb-afda-4242-b1a3-cd807e33c3d8"},{"cell_type":"markdown","source":["### Create and Load tables from CSV files\n","This cell creates a function to read raw data from the _Files_ section of the lakehouse for the table name passed as a parameter. Next, it creates a list of tables. Finally, it has a _for loop_ to loop through the list of tables and call above function with each table name as parameter to read data for that specific table and create delta table."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"74b43fe4-8805-4c74-90e9-4c8fa9ce826d"},{"cell_type":"code","source":["from pyspark.sql.types import *\n","\n","def loadFullDataFromSource(table_name):\n","    df = spark.read.option(\"inferSchema\",\"true\").option(\"header\",\"true\").format(\"csv\").load(\"Files/raw/\" + table_name +\".csv\")\n","\n","\n","    df.write.mode(\"overwrite\").format(\"delta\").save(\"Tables/\" + table_name)\n","\n","full_tables = [\n","    \"Calendar\",\n","    \"CustomerGroupMapping\",\n","    \"CustomerGroups\",\n","    \"Customers\",\n","    \"Geography\",\n","    \"ProductCategories\",\n","    \"ProductSubCategories\",\n","    \"Products\",\n","    \"Promotions\",\n","    \"Stores\",\n","    \"StrategicCustomers\"\n","    ]\n","\n","for table in full_tables:\n","    loadFullDataFromSource(table)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ea3526fd-55a0-42a8-a35e-3bc563696570"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a307cd18-7f28-4dd7-82fc-7fa2e482f052"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"248bd845-017d-4063-8247-d90e8cff1402"},{"id":"b5e1c7e2-9258-499d-a525-63d7cba907d7"}],"default_lakehouse":"b5e1c7e2-9258-499d-a525-63d7cba907d7","default_lakehouse_name":"aprillakehouse","default_lakehouse_workspace_id":"766de3c0-4ef9-4852-9a5c-4b95137c006f"}}},"nbformat":4,"nbformat_minor":5}